# 引用原文精确定位调研

## 步骤

### 验证指定输出 offset + length

明确指定为字符数，中文字符为1

结果：输出的片段完全对不上

分析：模型输入的是分词后的token，所以它可能并不知道字符？可以试试用 token 位置

### 验证 token offset + length

明确指定为当前模型的原生Token位置

结果：仍不符

尝试问DeepSeek:
[token]定义为你的模型原生的分词/Tokenization算法的 1 个元素。
请输出以下文本总共的[token]个数:
测试LLM是否能理解token的概念

DeepSeek 输出时说自己无法调用 Tokenizer，只能输出估算结果

分析：Tokens 虽然是模型的原始输入，但它对模型来说是透明的，无法感知到底层的数据。就像人也无法理解神经元信号？

### 验证 LLM 是否能正确计算字符数

尝试各种模型以下问题：

```md
请输出[信源原文]的字符/char个数，并写明计算过程
[信源原文]:
# 2024年四川省交通运输行业发展统计公报
年末颁证民用航空机场17个。全年旅客吞吐量达到100万人次以上的机场6个，较上年末减少1个，按旅客吞吐量从高到低分别是：成都天府国际机场、成都双流国际机场、绵阳南郊机场、泸州云龙机场、宜宾五粮液机场、达州金垭机场。全年货邮吞吐量达到1000吨以上的机场8个，较上年末持平，按货邮吞吐量从高到低分别是：成都双流国际机场、成都天府国际机场、宜宾五粮液机场、绵阳南郊机场、泸州云龙机场、南充高坪机场、达州金垭机场、西昌青山机场。
```

各家模型返回的值都不确定，每次都有差异。甚至 qwen-turbo 输出了以下推理：

```md
- `2024年四川省交通运输行业发展统计公报`：共23个字符（“2024年”4个，“四川省”3个，“交通运输”4个，“行业”2个，“发展”2个，“统计”2个，“公报”2个）
- 换行符：1个
- `年末颁证民用航空机场17个。`：共22个字符（“年末颁证民用航空机场”17个，“17个。”4个，其中“。”是1个
```

其中明显的错误处在于：
“2024年”4个
“年末颁证民用航空机场”17个
“17个。”4个

换 DeepSeek 也有同样的问题，精简到一句话都能统计出错：

```md
请输出[信源原文]的字符/char个数，并写明计算过程
[信源原文]:
2024年四川省交通运输行业发展统计公报
```

输出

```md
好的，我们来计算您提供的【信源原文】的字符个数。

**【信源原文】**
`2024年四川省交通运输行业发展统计公报`

**【计算过程】**
字符计数的基本原则是：计算字符串中所有字符的数量，包括汉字、数字、标点符号、英文字母等。在这个字符串中：
1.  数字字符有：`2`, `0`, `2`, `4`，共 **4** 个。
2.  汉字字符有：`四`, `川`, `省`, `交`, `通`, `运`, `输`, `行`, `业`, `发`, `展`, `统`, `计`, `公`, `报`，共 **15** 个。

字符串中没有空格、英文字母或其他标点符号。

**【字符总数】**
总字符数 = 数字字符数 + 汉字字符数 = 4 + 15 = **19** 个。

**【最终结果】**
[信源原文]的字符/char个数为：**19**。
```

## 结论

让模型直接输出 offset / limit 的方案不可行，如果想要精确定位，还是得让它输出原文，再用工程手段进行匹配
